{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data fetching and pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "con = psycopg2.connect(database=\"twitter\", host=\"localhost\", port=\"5432\", user=\"postgres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<connection object at 0x12e488180; dsn: 'dbname=twitter user=postgres host=localhost port=5432', closed: 0>\n"
     ]
    }
   ],
   "source": [
    "print(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_data = \"SELECT * from public.bangalore_tweets limit 1000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor.execute(get_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultset = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for row in resultset:\n",
    "    tweet = {}\n",
    "    json_tweet = json.loads(json.dumps(row[2][0]))    \n",
    "    if json_tweet.has_key(\"contributors\"):\n",
    "        tweet['text'] = json_tweet[\"text\"]\n",
    "    elif json_tweet.has_key(\"retweeted_status\"):\n",
    "        tweet['text'] = json_tweet[\"retweeted_status\"][\"text\"]\n",
    "    else:\n",
    "        continue\n",
    "    tweet['text'] = row[2][0]['text']\n",
    "    tweet['trend'] = row[3]\n",
    "    tweet['date'] = row[4]\n",
    "    tweet['hashtags'] = [ht['text'] for ht in row[2][0]['entities']['hashtags']]\n",
    "    \n",
    "    tweet_list.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trend': 'NaMo', 'text': u'#elections2014 yash for #NaMo http://t.co/v7W39Gzy9x', 'hashtags': [u'elections2014', u'NaMo'], 'date': datetime.date(2014, 4, 17)} {'trend': 'Karnataka', 'text': u'#Karnataka Jayapal is new Chief Executive of CEMILAC: P. Jayapal has taken charge as the new Chief Executive of... http://t.co/OR4aa9mrhK', 'hashtags': [u'Karnataka'], 'date': datetime.date(2014, 4, 17)}\n"
     ]
    }
   ],
   "source": [
    "print tweet_list[0],tweet_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleaner(sentence):\n",
    "    words = sentence.split()\n",
    "    word_list = [re.sub('http.*', '', word) for word in words if not word in stopwords.words(\"english\")]\n",
    "    return ' '.join(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def join_lines(sentence):\n",
    "    sentence = re.sub('\\n','.',sentence)\n",
    "    return sentence.encode('ascii','ignore')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tweet in tweet_list:\n",
    "    try:\n",
    "        tweet['text'] = join_lines(tweet['text'])\n",
    "        tweet['clean_text'] = cleaner(tweet['text'])\n",
    "    except Exception as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clean_text': '#elections2014 yash #NaMo ',\n",
       " 'date': datetime.date(2014, 4, 17),\n",
       " 'hashtags': [u'elections2014', u'NaMo'],\n",
       " 'text': '#elections2014 yash for #NaMo http://t.co/v7W39Gzy9x',\n",
       " 'trend': 'NaMo'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tweet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"tweets_mini.csv\",encoding='utf-8',quoting=csv.QUOTE_MINIMAL,doublequote=False,escapechar=\"\\\\\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv(\"tweets_mini.csv\",sep=\"\\t\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating TFIDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(decode_error='ignore', norm='l2')\n",
    "X = vectorizer.fit_transform(df['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "column_labels = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "column_matrix = csc_matrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_matrix = pd.DataFrame(column_matrix.toarray(),columns=column_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yuvraj = tfidf_matrix['yuvrajsingh'].copy()\n",
    "yuv = pd.Series(yuvraj, copy=True)\n",
    "x = yuv.sort(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "column_max_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,column in tfidf_matrix.iteritems():\n",
    "    column_max_list.append(column.max())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_max_df = pd.DataFrame([column_max_list,column_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "column_max_df = column_max_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_sorted = column_max_df.sort(columns=[0],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf_sorted[0][tfidf_sorted[0] == 1] = 0.99\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_tfidf = tfidf_sorted[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert term and tweets into DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for term in top_tfidf[1]:\n",
    "    related_tweet_list = []\n",
    "    for tweet in tweet_list:\n",
    "        if tweet['clean_text'].find(term) != -1: \n",
    "            related_tweet_list.append(tweet['text'])\n",
    "            \n",
    "    query = \"INSERT INTO TERM_TWEETS VALUES(%s,%s)\"\n",
    "    cursor.execute(query,(term,related_tweet_list))\n",
    "    con.commit()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Sentiment Analyser model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NEG_DIRECTORY = os.path.join('twitter_neg')\n",
    "POS_DIRECTORY = os.path.join('twitter_pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_reviews = []\n",
    "neg_reviews = []\n",
    "\n",
    "for pos_file in os.listdir(POS_DIRECTORY):\n",
    "    fileName = os.path.join(POS_DIRECTORY,pos_file)\n",
    "    with open(fileName, 'r') as posFile:\n",
    "        pos_reviews.extend(posFile.readlines())\n",
    "        \n",
    "for neg_file in os.listdir(NEG_DIRECTORY):\n",
    "    fileName = os.path.join(NEG_DIRECTORY,neg_file)\n",
    "    with open(fileName, 'r') as negFile:\n",
    "        neg_reviews.extend(negFile.readlines())\n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#building a numpy array by setting postive as 1 and negative as 0\n",
    "concatenated_array = np.concatenate((np.ones(len(pos_reviews)),np.zeros(len(neg_reviews))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_reviews_cleaned = []\n",
    "neg_reviews_cleaned = []\n",
    "\n",
    "#Do some very minor text preprocessing\n",
    "def cleanText(corpus):\n",
    "    punctuation = \"\"\".,?!:;(){}[]\"\"\"\n",
    "    corpus = [z.lower().replace('\\n','') for z in corpus]\n",
    "    corpus = [z.replace('<br />', ' ') for z in corpus]\n",
    "\n",
    "    #treat punctuation as individual words\n",
    "    for c in punctuation:\n",
    "        corpus = [z.replace(c, ' %s '%c) for z in corpus]\n",
    "    corpus = [z.split() for z in corpus]\n",
    "    return corpus\n",
    "\n",
    "pos_reviews_cleaned = cleanText(pos_reviews)\n",
    "neg_reviews_cleaned = cleanText(neg_reviews)\n",
    "\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train,x_test,pos_neg_train,pos_neg_test = train_test_split(np.concatenate((pos_reviews_cleaned,neg_reviews_cleaned)),concatenated_array,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "LabeledSentence = gensim.models.doc2vec.LabeledSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labelizeReviews(reviews,label_type):\n",
    "    labelized = []\n",
    "    for i,v in enumerate(reviews):\n",
    "        if len(v) ==0:\n",
    "            continue\n",
    "        label = '%s_%s'%(label_type,i)\n",
    "        labelized.append(LabeledSentence(v,[label]))\n",
    "    return labelized\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_label = labelizeReviews(x_train,'TRAIN')\n",
    "x_test_label = labelizeReviews(x_test,'TEST')\n",
    "unsup_reviews = []\n",
    "for tweet in tweet_list:\n",
    "    unsup_reviews.append(tweet['clean_text'])\n",
    "\n",
    "unsup_lable_reviews = labelizeReviews(unsup_reviews,'UNSUP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We have labelized reviews, now running DBOW/DM to build the model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 300\n",
    "\n",
    "model_dm = gensim.models.Doc2Vec(min_count=1,window=10,size=size,sample=1e-3,negative=5,workers=4)\n",
    "model_dbow = gensim.models.Doc2Vec(min_count=1,window=10,size=size,sample=1e-3,negative=5,workers=4,dm=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_dm.build_vocab(np.concatenate((x_train_label,x_test_label,unsup_lable_reviews)))\n",
    "model_dbow.build_vocab(np.concatenate((x_train_label,x_test_label,unsup_lable_reviews)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_train_reviews = np.concatenate((x_train_label,unsup_lable_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9530"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_reviews.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    perm = np.random.permutation(all_train_reviews.shape[0])\n",
    "    model_dm.train(all_train_reviews[perm])\n",
    "    model_dbow.train(all_train_reviews[perm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getVecs(model,corpus,size):\n",
    "    vecs = [np.array(model[z.labels[0]]).reshape((1,size)) for z in corpus]\n",
    "    return np.concatenate(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_vecs_dm = getVecs(model_dm,x_train_label,size)\n",
    "train_vecs_dbow = getVecs(model_dbow,x_train_label,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_vecs = np.hstack((train_vecs_dm,train_vecs_dbow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8530, 600)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test_label = np.array(x_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    perm = np.random.permutation(x_test_label.shape[0])\n",
    "    model_dm.train(x_test_label[perm])\n",
    "    model_dbow.train(x_test_label[perm])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_vecs_dm = getVecs(model_dm,x_test_label,size)\n",
    "test_vecs_dbow = getVecs(model_dbow,x_test_label,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_vecs = np.hstack((test_vecs_dm,test_vecs_dbow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2133,)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_neg_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We have all the vectors now, we have to train the classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, class_weight=None, epsilon=0.1, eta0=0.0,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='optimal',\n",
       "       loss='log', n_iter=5, n_jobs=1, penalty='l1', power_t=0.5,\n",
       "       random_state=None, shuffle=False, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrl1 = SGDClassifier(loss='log',penalty='l1')\n",
    "lrl1.fit(train_vecs,pos_neg_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.62\n"
     ]
    }
   ],
   "source": [
    "print 'Test Accuracy : %.2f' %lrl1.score(test_vecs,pos_neg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.61\n"
     ]
    }
   ],
   "source": [
    "lrl2 = SGDClassifier(loss='log',penalty='l2')\n",
    "lrl2.fit(train_vecs,pos_neg_train)\n",
    "print 'Test Accuracy : %.2f' %lrl2.score(test_vecs,pos_neg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.52\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=20)\n",
    "rfc.fit(train_vecs,pos_neg_train)\n",
    "print 'Test Accuracy: %.2f' %rfc.score(test_vecs,pos_neg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing Data and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unsup_dm = getVecs(model_dm,unsup_lable_reviews,size)\n",
    "unsup_dbow = getVecs(model_dbow, unsup_lable_reviews, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unsup_vecs = np.hstack((unsup_dm, unsup_dbow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unsup_label_predict = lrl2.predict(unsup_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = []\n",
    "clear_tweets = []\n",
    "for tweet in tweet_list:\n",
    "    tweets.append(tweet['text'])\n",
    "    clear_tweets.append(tweet['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_df = pd.DataFrame({'tweet':tweets,'prediction':unsup_label_predict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildLabelVectorAndPredict(tweets):\n",
    "    test_vector_lable_reviews = labelizeReviews(tweets[0],'UNSUP')\n",
    "    test_vector_dm = getVecs(model_dm,test_vector_lable_reviews,size)\n",
    "    test_vector_dbow = getVecs(model_dbow, test_vector_lable_reviews, size)\n",
    "    test_vector_set = np.hstack((test_vector_dm,test_vector_dbow))\n",
    "    return lrl2.predict(test_vector_set)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trend_sentiment = {}\n",
    "for trend in top_tfidf[1]:\n",
    "    getQuery = \"SELECT tweets from term_tweets where term=%s\"\n",
    "    cursor.execute(getQuery,(trend,))\n",
    "    related_tweets = cursor.fetchone()\n",
    "    if len(related_tweets[0]) < 5:\n",
    "        continue\n",
    "    predicted_score = buildLabelVectorAndPredict(related_tweets)\n",
    "    df_predicted_result = pd.DataFrame(predicted_score, columns=['predict'])\n",
    "    x = df_predicted_result.predict.value_counts()\n",
    "    trend_sentiment[trend] = float(1*x[1])/ float(x[0]+x[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame.from_dict(trend_sentiment,orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td> 0.979827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lore</th>\n",
       "      <td> 0.972028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td> 0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ls</th>\n",
       "      <td> 0.945205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>now</th>\n",
       "      <td> 0.931034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elect</th>\n",
       "      <td> 0.931034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voted</th>\n",
       "      <td> 0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td> 0.925926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kannakeepcalm</th>\n",
       "      <td> 0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rm</th>\n",
       "      <td> 0.918367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td> 0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boot</th>\n",
       "      <td> 0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interview</th>\n",
       "      <td> 0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cricket</th>\n",
       "      <td> 0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td> 0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ji</th>\n",
       "      <td> 0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ready</th>\n",
       "      <td> 0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cast</th>\n",
       "      <td> 0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hindu</th>\n",
       "      <td> 0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "he             0.979827\n",
       "lore           0.972028\n",
       "go             0.954545\n",
       "ls             0.945205\n",
       "now            0.931034\n",
       "elect          0.931034\n",
       "voted          0.928571\n",
       "film           0.925926\n",
       "kannakeepcalm  0.923077\n",
       "rm             0.918367\n",
       "want           0.904762\n",
       "boot           0.900000\n",
       "interview      0.900000\n",
       "cricket        0.888889\n",
       "year           0.882353\n",
       "ji             0.875000\n",
       "ready          0.857143\n",
       "cast           0.833333\n",
       "hindu          0.800000"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.sort(columns=[0],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
